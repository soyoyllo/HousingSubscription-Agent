import os
import asyncio
from typing import List, Dict, Optional, Any
from pathlib import Path
from dataclasses import dataclass, field
import logging

# PDF ì²˜ë¦¬
import pymupdf4llm
import fitz  # PyMuPDF

# Vector Store & Embeddings
from langchain_community.vectorstores import Chroma
from langchain_openai import OpenAIEmbeddings
from langchain.text_splitter import MarkdownHeaderTextSplitter, RecursiveCharacterTextSplitter

# RAG Components
from langchain_openai import ChatOpenAI
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
from langchain_core.documents import Document

# ê¸°ì¡´ ëª¨ë¸ë“¤
from dataclasses import dataclass

@dataclass
class NoticeInfo:
    ê³µê³ ëª…: str
    ê³µê³ URL: str
    ê³µê³ ê²Œì‹œì¼: str
    PDF_PATH: str  # PDF íŒŒì¼ ê²½ë¡œ ì¶”ê°€
    MARKDOWN_PATH: str = ""  # ë³€í™˜ëœ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ê²½ë¡œ
    ëª¨ì§‘ë§ˆê°ì¼: Optional[str] = None
    ê³µê³ ìƒíƒœ: Optional[str] = None
    ì²­ì•½ìœ í˜•: Optional[str] = None
    ê³µê³ ì§€ì—­: Optional[str] = 'ì„œìš¸íŠ¹ë³„ì‹œ'

@dataclass 
class RAGConfig:
    """RAG ì„¤ì •"""
    chunk_size: int = 1000
    chunk_overlap: int = 200
    embedding_model: str = "text-embedding-3-small"
    llm_model: str = "gpt-4.1-mini"
    vector_store_path: str = "./notice_vectorstore"
    temperature: float = 0.1
    top_k: int = 5

class NoticeRAGPipeline:
    """Notice RAG íŒŒì´í”„ë¼ì¸ ë©”ì¸ í´ë˜ìŠ¤"""
    
    def __init__(self, config: RAGConfig):
        self.config = config
        self.embeddings = OpenAIEmbeddings(model=config.embedding_model)
        self.llm = ChatOpenAI(
            model=config.llm_model,
            temperature=config.temperature
        )
        self.vector_store = None
        self.setup_logging()
        
    def setup_logging(self):
        """ë¡œê¹… ì„¤ì •"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        self.logger = logging.getLogger(__name__)

    # ==================== 1. PDF â†’ Markdown ë³€í™˜ ====================
    
    async def pdf_to_markdown(self, notice_info: NoticeInfo) -> str:
        """PyMuPDF4llmì„ ì‚¬ìš©í•´ì„œ PDFë¥¼ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ë³€í™˜"""
        try:
            self.logger.info(f"PDF ë³€í™˜ ì‹œì‘: {notice_info.ê³µê³ ëª…}")
            
            # PDF íŒŒì¼ ì¡´ì¬ í™•ì¸
            if not os.path.exists(notice_info.PDF_PATH):
                raise FileNotFoundError(f"PDF íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {notice_info.PDF_PATH}")
            
            # PyMuPDF4llmìœ¼ë¡œ ë§ˆí¬ë‹¤ìš´ ë³€í™˜
            markdown_content = pymupdf4llm.to_markdown(
                doc=notice_info.PDF_PATH,
                page_chunks=True,  # í˜ì´ì§€ë³„ ì²­í¬ ìƒì„±
                write_images=False,  # ì´ë¯¸ì§€ëŠ” ì œì™¸
                embed_images=False,  # ì´ë¯¸ì§€ ì„ë² ë”© ì œì™¸
                extract_words=True,  # ë‹¨ì–´ ë‹¨ìœ„ ì¶”ì¶œ
                extract_tables=True,  # í‘œ êµ¬ì¡° ë³´ì¡´
            )
            
            # ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ì €ì¥
            markdown_dir = Path("./markdown_notices")
            markdown_dir.mkdir(exist_ok=True)
            
            # íŒŒì¼ëª… ìƒì„± (ê³µê³ ëª… ê¸°ë°˜)
            safe_filename = self._sanitize_filename(notice_info.ê³µê³ ëª…)
            markdown_path = markdown_dir / f"{safe_filename}.md"
            
            # ë©”íƒ€ë°ì´í„° ì¶”ê°€
            metadata_header = self._create_metadata_header(notice_info)
            full_content = metadata_header + "\n\n" + markdown_content
            
            # íŒŒì¼ ì €ì¥
            with open(markdown_path, 'w', encoding='utf-8') as f:
                f.write(full_content)
            
            # NoticeInfo ì—…ë°ì´íŠ¸
            notice_info.MARKDOWN_PATH = str(markdown_path)
            
            self.logger.info(f"ë§ˆí¬ë‹¤ìš´ ë³€í™˜ ì™„ë£Œ: {markdown_path}")
            return full_content
            
        except Exception as e:
            self.logger.error(f"PDF ë³€í™˜ ì˜¤ë¥˜: {str(e)}")
            raise
    
    def _sanitize_filename(self, filename: str) -> str:
        """íŒŒì¼ëª…ì—ì„œ íŠ¹ìˆ˜ë¬¸ì ì œê±°"""
        import re
        # í•œê¸€, ì˜ë¬¸, ìˆ«ì, í•˜ì´í”ˆ, ì–¸ë”ìŠ¤ì½”ì–´ë§Œ í—ˆìš©
        safe_name = re.sub(r'[^\w\s-]', '', filename.strip())
        safe_name = re.sub(r'[-\s]+', '-', safe_name)
        return safe_name[:50]  # ê¸¸ì´ ì œí•œ
    
    def _create_metadata_header(self, notice_info: NoticeInfo) -> str:
        """ë§ˆí¬ë‹¤ìš´ ë©”íƒ€ë°ì´í„° í—¤ë” ìƒì„±"""
        return f"""---
ê³µê³ ëª…: {notice_info.ê³µê³ ëª…}
ê³µê³ URL: {notice_info.ê³µê³ URL}
ê³µê³ ê²Œì‹œì¼: {notice_info.ê³µê³ ê²Œì‹œì¼}
ëª¨ì§‘ë§ˆê°ì¼: {notice_info.ëª¨ì§‘ë§ˆê°ì¼}
ì²­ì•½ìœ í˜•: {notice_info.ì²­ì•½ìœ í˜•}
ê³µê³ ì§€ì—­: {notice_info.ê³µê³ ì§€ì—­}
ìƒì„±ì¼ì‹œ: {pd.Timestamp.now().isoformat()}
---

# {notice_info.ê³µê³ ëª…}
"""
    
    # ==================== 2. ë§ˆí¬ë‹¤ìš´ ì²­í‚¹ ====================
    
    def chunk_markdown(self, markdown_content: str, notice_info: NoticeInfo) -> List[Document]:
        """ë§ˆí¬ë‹¤ìš´ ë‚´ìš©ì„ êµ¬ì¡°í™”ëœ ì²­í¬ë¡œ ë¶„í• """
        try:
            self.logger.info(f"ë§ˆí¬ë‹¤ìš´ ì²­í‚¹ ì‹œì‘: {notice_info.ê³µê³ ëª…}")
            
            # 1ë‹¨ê³„: í—¤ë” ê¸°ë°˜ ë¶„í• 
            headers_to_split_on = [
                ("#", "Header 1"),
                ("##", "Header 2"), 
                ("###", "Header 3"),
                ("####", "Header 4"),
            ]
            
            markdown_splitter = MarkdownHeaderTextSplitter(
                headers_to_split_on=headers_to_split_on,
                strip_headers=False
            )
            
            header_splits = markdown_splitter.split_text(markdown_content)
            
            # 2ë‹¨ê³„: ê¸¸ì´ ê¸°ë°˜ ì¶”ê°€ ë¶„í• 
            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=self.config.chunk_size,
                chunk_overlap=self.config.chunk_overlap,
                separators=["\n\n", "\n", ".", "!", "?", ",", " ", ""]
            )
            
            # ê° í—¤ë” ì²­í¬ë¥¼ ë” ì‘ì€ ì²­í¬ë¡œ ë¶„í• 
            final_chunks = []
            for doc in header_splits:
                if len(doc.page_content) > self.config.chunk_size:
                    sub_chunks = text_splitter.split_documents([doc])
                    final_chunks.extend(sub_chunks)
                else:
                    final_chunks.append(doc)
            
            # ë©”íƒ€ë°ì´í„° ì¶”ê°€
            for i, chunk in enumerate(final_chunks):
                chunk.metadata.update({
                    "ê³µê³ ëª…": notice_info.ê³µê³ ëª…,
                    "ê³µê³ URL": notice_info.ê³µê³ URL,
                    "ì²­ì•½ìœ í˜•": notice_info.ì²­ì•½ìœ í˜•,
                    "ê³µê³ ì§€ì—­": notice_info.ê³µê³ ì§€ì—­,
                    "chunk_id": f"{notice_info.ê³µê³ ëª…}_chunk_{i}",
                    "source": notice_info.PDF_PATH
                })
            
            self.logger.info(f"ì²­í‚¹ ì™„ë£Œ: {len(final_chunks)}ê°œ ì²­í¬ ìƒì„±")
            return final_chunks
            
        except Exception as e:
            self.logger.error(f"ì²­í‚¹ ì˜¤ë¥˜: {str(e)}")
            raise
    
    # ==================== 3. Vector Store êµ¬ì¶• ====================
    
    async def build_vector_store(self, chunks: List[Document], notice_info: NoticeInfo):
        """ë²¡í„° ìŠ¤í† ì–´ êµ¬ì¶•"""
        try:
            self.logger.info(f"ë²¡í„° ìŠ¤í† ì–´ êµ¬ì¶• ì‹œì‘: {notice_info.ê³µê³ ëª…}")
            
            # ë²¡í„° ìŠ¤í† ì–´ ë””ë ‰í† ë¦¬ ìƒì„±
            vector_store_dir = Path(self.config.vector_store_path)
            vector_store_dir.mkdir(exist_ok=True)
            
            # ê³µê³ ë³„ ê°œë³„ ë²¡í„° ìŠ¤í† ì–´ ìƒì„±
            notice_vector_path = vector_store_dir / self._sanitize_filename(notice_info.ê³µê³ ëª…)
            
            # Chroma ë²¡í„° ìŠ¤í† ì–´ ìƒì„±
            vector_store = Chroma.from_documents(
                documents=chunks,
                embedding=self.embeddings,
                persist_directory=str(notice_vector_path),
                collection_name=f"notice_{self._sanitize_filename(notice_info.ê³µê³ ëª…)}"
            )
            
            # ë²¡í„° ìŠ¤í† ì–´ ì €ì¥
            vector_store.persist()
            
            self.logger.info(f"ë²¡í„° ìŠ¤í† ì–´ êµ¬ì¶• ì™„ë£Œ: {notice_vector_path}")
            return vector_store
            
        except Exception as e:
            self.logger.error(f"ë²¡í„° ìŠ¤í† ì–´ êµ¬ì¶• ì˜¤ë¥˜: {str(e)}")
            raise
    
    # ==================== 4. ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œ ====================
    
    def load_vector_store(self, notice_info: NoticeInfo):
        """ê¸°ì¡´ ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ"""
        try:
            vector_store_dir = Path(self.config.vector_store_path)
            notice_vector_path = vector_store_dir / self._sanitize_filename(notice_info.ê³µê³ ëª…)
            
            if notice_vector_path.exists():
                self.vector_store = Chroma(
                    persist_directory=str(notice_vector_path),
                    embedding_function=self.embeddings,
                    collection_name=f"notice_{self._sanitize_filename(notice_info.ê³µê³ ëª…)}"
                )
                self.logger.info(f"ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ ì™„ë£Œ: {notice_vector_path}")
                return True
            else:
                self.logger.warning(f"ë²¡í„° ìŠ¤í† ì–´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {notice_vector_path}")
                return False
                
        except Exception as e:
            self.logger.error(f"ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ ì˜¤ë¥˜: {str(e)}")
            return False
    
    def create_qa_chain(self, notice_info: NoticeInfo):
        """ì§ˆì˜ì‘ë‹µ ì²´ì¸ ìƒì„±"""
        if not self.vector_store:
            raise ValueError("ë²¡í„° ìŠ¤í† ì–´ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜
        prompt_template = """
ë‹¹ì‹ ì€ ì£¼íƒ ì²­ì•½ ê³µê³ ë¬¸ ì „ë¬¸ ìƒë‹´ì‚¬ì…ë‹ˆë‹¤. 
ì£¼ì–´ì§„ ê³µê³ ë¬¸ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì •í™•í•˜ê³  ìƒì„¸í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.

ê³µê³ ë¬¸ ì •ë³´:
- ê³µê³ ëª…: {notice_name}
- ì²­ì•½ìœ í˜•: {notice_type}
- ì§€ì—­: {notice_area}

ê´€ë ¨ ë¬¸ì„œ ë‚´ìš©:
{context}

ì‚¬ìš©ì ì§ˆë¬¸: {question}

ë‹µë³€ ê°€ì´ë“œë¼ì¸:
1. ê³µê³ ë¬¸ì— ëª…ì‹œëœ ë‚´ìš©ë§Œì„ ê·¼ê±°ë¡œ ë‹µë³€í•˜ì„¸ìš”
2. êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ë‚˜ ì¡°ê±´ì´ ìˆë‹¤ë©´ ì •í™•íˆ ì¸ìš©í•˜ì„¸ìš”
3. ë¶ˆë¶„ëª…í•œ ë¶€ë¶„ì€ "ê³µê³ ë¬¸ì— ëª…ì‹œë˜ì§€ ì•ŠìŒ"ì´ë¼ê³  í‘œì‹œí•˜ì„¸ìš”
4. ë‹µë³€ì„ êµ¬ì¡°í™”í•˜ì—¬ ì´í•´í•˜ê¸° ì‰½ê²Œ ì‘ì„±í•˜ì„¸ìš”
5. í•„ìš”ì‹œ ê´€ë ¨ ì„¹ì…˜ì´ë‚˜ í˜ì´ì§€ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”

ë‹µë³€:
"""
        
        prompt = PromptTemplate(
            template=prompt_template,
            input_variables=["context", "question", "notice_name", "notice_type", "notice_area"]
        )
        
        # RetrievalQA ì²´ì¸ ìƒì„±
        qa_chain = RetrievalQA.from_chain_type(
            llm=self.llm,
            chain_type="stuff",
            retriever=self.vector_store.as_retriever(
                search_kwargs={"k": self.config.top_k}
            ),
            chain_type_kwargs={
                "prompt": prompt,
                "document_variable_name": "context"
            },
            return_source_documents=True
        )
        
        # ê³µê³  ì •ë³´ë¥¼ ì¶”ê°€í•˜ëŠ” ë˜í¼ í•¨ìˆ˜
        def enhanced_qa(question: str) -> Dict[str, Any]:
            result = qa_chain.invoke({
                "query": question,
                "notice_name": notice_info.ê³µê³ ëª…,
                "notice_type": notice_info.ì²­ì•½ìœ í˜•,
                "notice_area": notice_info.ê³µê³ ì§€ì—­
            })
            
            # ì†ŒìŠ¤ ë¬¸ì„œ ì •ë³´ ì¶”ê°€
            sources = []
            for doc in result.get("source_documents", []):
                sources.append({
                    "content": doc.page_content[:200] + "...",
                    "metadata": doc.metadata
                })
            
            return {
                "answer": result["result"],
                "sources": sources,
                "notice_info": {
                    "ê³µê³ ëª…": notice_info.ê³µê³ ëª…,
                    "ì²­ì•½ìœ í˜•": notice_info.ì²­ì•½ìœ í˜•,
                    "ê³µê³ ì§€ì—­": notice_info.ê³µê³ ì§€ì—­
                }
            }
        
        return enhanced_qa
    
    # ==================== 5. ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ====================
    
    async def process_notice(self, notice_info: NoticeInfo) -> bool:
        """ê³µê³ ë¬¸ ì „ì²´ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸"""
        try:
            self.logger.info(f"ê³µê³ ë¬¸ ì²˜ë¦¬ ì‹œì‘: {notice_info.ê³µê³ ëª…}")
            
            # 1. PDF â†’ Markdown ë³€í™˜
            markdown_content = await self.pdf_to_markdown(notice_info)
            
            # 2. ë§ˆí¬ë‹¤ìš´ ì²­í‚¹
            chunks = self.chunk_markdown(markdown_content, notice_info)
            
            # 3. ë²¡í„° ìŠ¤í† ì–´ êµ¬ì¶•
            await self.build_vector_store(chunks, notice_info)
            
            self.logger.info(f"ê³µê³ ë¬¸ ì²˜ë¦¬ ì™„ë£Œ: {notice_info.ê³µê³ ëª…}")
            return True
            
        except Exception as e:
            self.logger.error(f"ê³µê³ ë¬¸ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
            return False
    
    def query_notice(self, notice_info: NoticeInfo, question: str) -> Dict[str, Any]:
        """ê³µê³ ë¬¸ ì§ˆì˜ì‘ë‹µ"""
        try:
            # ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ
            if not self.load_vector_store(notice_info):
                raise ValueError("í•´ë‹¹ ê³µê³ ë¬¸ì˜ ë²¡í„° ìŠ¤í† ì–´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            # QA ì²´ì¸ ìƒì„±
            qa_function = self.create_qa_chain(notice_info)
            
            # ì§ˆì˜ì‘ë‹µ ì‹¤í–‰
            result = qa_function(question)
            
            self.logger.info(f"ì§ˆì˜ì‘ë‹µ ì™„ë£Œ: {question[:50]}...")
            return result
            
        except Exception as e:
            self.logger.error(f"ì§ˆì˜ì‘ë‹µ ì˜¤ë¥˜: {str(e)}")
            raise

# ==================== ì‚¬ìš© ì˜ˆì‹œ ====================

async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    
    # RAG ì„¤ì •
    config = RAGConfig(
        chunk_size=800,
        chunk_overlap=100,
        top_k=3
    )
    
    # íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”
    rag_pipeline = NoticeRAGPipeline(config)
    
    # ê³µê³ ë¬¸ ì •ë³´ (ì˜ˆì‹œ)
    notice_info = NoticeInfo(
        ê³µê³ ëª…="LH ì²­ë…„ì „ì„¸ì„ëŒ€ì£¼íƒ 2024ë…„ 1ì°¨ ê³µê³ ",
        ê³µê³ URL="https://example.com/notice1",
        ê³µê³ ê²Œì‹œì¼="2024-01-15",
        PDF_PATH="./notices/LH_ì²­ë…„ì „ì„¸ì„ëŒ€_2024_1ì°¨.pdf",
        ì²­ì•½ìœ í˜•="ì „ì„¸ì„ëŒ€",
        ê³µê³ ì§€ì—­="ì„œìš¸íŠ¹ë³„ì‹œ"
    )
    
    try:
        # 1. ê³µê³ ë¬¸ ì²˜ë¦¬ (PDF â†’ Markdown â†’ Vector Store)
        success = await rag_pipeline.process_notice(notice_info)
        
        if success:
            print("âœ… ê³µê³ ë¬¸ ì²˜ë¦¬ ì™„ë£Œ!")
            
            # 2. ì§ˆì˜ì‘ë‹µ í…ŒìŠ¤íŠ¸
            questions = [
                "ì´ ê³µê³ ì˜ ìê²© ìš”ê±´ì´ ë¬´ì—‡ì¸ê°€ìš”?",
                "ì‹ ì²­ ë°©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”",
                "ì„ëŒ€ë£Œì™€ ë³´ì¦ê¸ˆì€ ì–¼ë§ˆì¸ê°€ìš”?",
                "ì‹ ì²­ ë§ˆê°ì¼ì€ ì–¸ì œì¸ê°€ìš”?"
            ]
            
            for question in questions:
                print(f"\nâ“ ì§ˆë¬¸: {question}")
                result = rag_pipeline.query_notice(notice_info, question)
                print(f"ğŸ’¬ ë‹µë³€: {result['answer']}")
                print(f"ğŸ“š ì°¸ì¡° ë¬¸ì„œ: {len(result['sources'])}ê°œ")
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

if __name__ == "__main__":
    import pandas as pd
    asyncio.run(main())